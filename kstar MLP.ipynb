{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal is to make multilayer perceptron that, given a simple two polymer (2 monomer each) binary mix, can predict \n",
    "#whether the system will micro or macro phase separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import wlcstat.wlc_copoly as wlc_copoly\n",
    "import wlcstat.wlcstruc as wlcstruc\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./vertex_subroutines\")\n",
    "from GAMcalc import *  # Code for calculating vertex functions\n",
    "import propagator  # propagator object used to store pre-calculated values\n",
    "import wignerD as wd # wigner D object used to store pre-calculated values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "pset=propagator.prop_set(nlam=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_monomer_matrix(poly_mat, dens):\n",
    "    # calculates the AA monomer identity cross correlation matrix\n",
    "    # assumes all polymers same length/ # of monomers, equal volume fraction of each\n",
    "    \n",
    "    #polymat - each row is a polymer\n",
    "    #dens is an array where each entry is rel vol frac of correponding polymer\n",
    "    if (np.sum(dens) != 1):\n",
    "        raise Exception(\"polymer volumer fractions do not sum to one\")\n",
    "    if len(np.shape(poly_mat)) == 1: #single poly\n",
    "        n_p = 1\n",
    "        M = len(poly)\n",
    "        alph1 =np.zeros(M)\n",
    "        alph2 =np.zeros(M)\n",
    "        sig1 = 1*(poly == alph1)\n",
    "        sig2 = 1*(poly == alph2)\n",
    "        M2_AA = np.outer(sig1, sig2)\n",
    "        return M2_AA\n",
    "    \n",
    "    n_p = poly_mat.shape[0]\n",
    "    M = poly_mat.shape[1]\n",
    "    alph1 =np.zeros((n_p, M))\n",
    "    alph2 =np.zeros((n_p, M))\n",
    "    \n",
    "    #extend dens into n_pxM matrix\n",
    "    poly_weights = (np.ones((n_p, M)).T * dens).T\n",
    "    \n",
    "    #multiply sigams by density of each polymer\n",
    "    sigma1 = 1*((poly_mat == alph1))#.sum(axis = 0) #sigma. could multiply each\n",
    "    sigma2 = 1*((poly_mat == alph2))#.sum(axis = 0)\n",
    "\n",
    "    #need to do each row outer product with corresponding row, get n_p MxM matrices, then sum the results\n",
    "    prods = np.einsum('bi,bo->bio', sigma1*poly_weights, sigma2) # performing row wise cross product (each poly contribution)\n",
    "    M2_AA = np.sum(prods, axis = 0)#           ^^^^ averaging each contribution\n",
    "    return M2_AA\n",
    "\n",
    "def calc_sf2(poly_mat, dens, N_m=1, b=1, k_vec = np.logspace(-2, 2, 50)):\n",
    "    #calculates all variations of the S(2) AA AB BB for a range of k\n",
    "    M2_AA = calc_monomer_matrix(poly_mat, dens)\n",
    "    M = np.shape(M2_AA)[0]\n",
    "    nk = len(k_vec)\n",
    "\n",
    "    one = np.ones((M,M))\n",
    "    grid = np.indices((M, M))\n",
    "    S2_AA_arr = np.zeros(nk)\n",
    "    S2_AB_arr_fast = np.zeros(nk)\n",
    "    S2_BB_arr_fast = np.zeros(nk)\n",
    "\n",
    "\n",
    "    H_AA = np.diag(M2_AA)\n",
    "    H_AA_mat = (H_AA * one).T\n",
    "    for i, k in enumerate(k_vec):\n",
    "        C = np.zeros((M, M))\n",
    "        x_m = (1/6) * N_m * b**2 * k**2\n",
    "\n",
    "        #j1 = j2\n",
    "        debye = (2/(x_m**2)) * (x_m + np.exp(-x_m) - 1) * (1/M**2)\n",
    "\n",
    "        np.fill_diagonal(C, np.diag(one * debye))\n",
    "\n",
    "        integral = (1/(x_m**2)) * (np.exp(x_m) + np.exp(-x_m) - 2) #for off-diagonal terms\n",
    "\n",
    "        #j1 > j2\n",
    "        j1minusj2_mat = grid[0] - grid[1]\n",
    "        C += np.tril(one * np.exp(-x_m*(j1minusj2_mat)) * integral * (1/M**2), k = -1)\n",
    "\n",
    "        #j2 > j1\n",
    "        j2minusj1_mat = -1 * j1minusj2_mat\n",
    "        C += np.triu(one * np.exp(-x_m*(j2minusj1_mat)) * integral * (1/M**2), k = 1) \n",
    "        \n",
    "        \n",
    "        S2_AA_arr[i] = np.sum(C * M2_AA)\n",
    "\n",
    "\n",
    "        C_AB = H_AA_mat * C\n",
    "        S2_AB_arr_fast[i] = np.sum(C_AB) - S2_AA_arr[i]\n",
    "        S2_BB_arr_fast[i] = np.sum(C) + S2_AA_arr[i] - 2*np.sum(C_AB)\n",
    "    return (S2_AA_arr, S2_AB_arr_fast, S2_BB_arr_fast)\n",
    "\n",
    "def calc_sf2_inv(poly_mat, dens, N_m=1, b=1, k_vec = np.logspace(-2, 2, 50)):\n",
    "    (S2_AA_arr, S2_AB_arr, S2_BB_arr) = calc_sf2(poly_mat, dens, N_m, b, k_vec)\n",
    "    det = S2_AA_arr * S2_BB_arr - S2_AB_arr**2\n",
    "    S2_AA_inv = S2_BB_arr * (1/det)\n",
    "    S2_AB_inv = -S2_AB_arr * (1/det)\n",
    "    S2_BB_inv = S2_AA_arr * (1/det)\n",
    "    return (S2_AA_inv, S2_AB_inv, S2_BB_inv)\n",
    "\n",
    "def find_kstar(poly_mat, dens, N_m=1, b=1, k_vec = np.logspace(-2, 2, 50)):\n",
    "    (S2_AA_inv, S2_AB_inv, S2_BB_inv) = calc_sf2_inv(poly_mat, dens, N_m, b, k_vec)\n",
    "    G2 = 0.5*(S2_AA_inv - 2* S2_AB_inv + S2_BB_inv) # chi = 0\n",
    "\n",
    "    # eigvalues,eigvectors = np.linalg.eigh(G2)\n",
    "    eigvalues_lst = G2\n",
    "    min_eig = np.min(eigvalues_lst[~np.isnan(eigvalues_lst)])\n",
    "\n",
    "    k_star = k_vec[np.where(eigvalues_lst==min_eig)]#[0]][0] \n",
    "    return k_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get data\n",
    "\n",
    "\n",
    "diblocks = np.array([[0, 1], [0, 1]])\n",
    "diblocks_dens = [0.5, 0.5]\n",
    "diblocks_res = 1*(0.01 == find_kstar(diblocks, diblocks_dens, N_m=1, b=1, k_vec = np.logspace(-2, 2, 50)))\n",
    "\n",
    "homos = np.array([[1, 1], [0, 0]])\n",
    "homos_dens = diblocks_dens\n",
    "homos_res = 1*(0.01 == find_kstar(homos, homos_dens, N_m=1, b=1, k_vec = np.logspace(-2, 2, 50)))\n",
    "\n",
    "diblock_homo = np.array([[1, 1], [1, 0]])\n",
    "d_arr = np.arange(0.1, 0.91, 0.1)\n",
    "\n",
    "# dens = np.array([d, 1-d])\n",
    "# testres = 1*(0.01 == find_kstar(diblock_homo, dens, N_m=1, b=1, k_vec = np.logspace(-2, 2, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.append(np.append(diblocks.flatten(), diblocks_dens), diblocks_res)\n",
    "r2 = np.append(np.append(homos.flatten(), homos_dens), homos_res)\n",
    "data = np.vstack((r1, r2))\n",
    "\n",
    "for d in d_arr:\n",
    "    dens = np.array([d, 1-d])\n",
    "    res = 1*(0.01 == find_kstar(diblock_homo, dens, N_m=1, b=1, k_vec = np.logspace(-2, 2, 50)))\n",
    "    rn = np.append(np.append(diblock_homo.flatten(), dens) , res)\n",
    "    data = np.vstack((data, rn))\n",
    "#[p1m1 p1m2 p2m1 p2m2 p1d1 p2d2 macro?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. , 0. , 1. , 0.5, 0.5, 0. ],\n",
       "       [1. , 1. , 0. , 0. , 0.5, 0.5, 1. ],\n",
       "       [1. , 1. , 1. , 0. , 0.1, 0.9, 0. ],\n",
       "       [1. , 1. , 1. , 0. , 0.2, 0.8, 0. ],\n",
       "       [1. , 1. , 1. , 0. , 0.3, 0.7, 0. ],\n",
       "       [1. , 1. , 1. , 0. , 0.4, 0.6, 0. ],\n",
       "       [1. , 1. , 1. , 0. , 0.5, 0.5, 1. ],\n",
       "       [1. , 1. , 1. , 0. , 0.6, 0.4, 1. ],\n",
       "       [1. , 1. , 1. , 0. , 0.7, 0.3, 1. ],\n",
       "       [1. , 1. , 1. , 0. , 0.8, 0.2, 1. ],\n",
       "       [1. , 1. , 1. , 0. , 0.9, 0.1, 1. ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "#clms: [p1m1 p1m2 p2m1 p2m2 p1d1 p2d2 macro?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. , 0. , 1. , 0.5, 0.5],\n",
       "       [1. , 1. , 0. , 0. , 0.5, 0.5],\n",
       "       [1. , 1. , 1. , 0. , 0.1, 0.9],\n",
       "       [1. , 1. , 1. , 0. , 0.2, 0.8],\n",
       "       [1. , 1. , 1. , 0. , 0.3, 0.7],\n",
       "       [1. , 1. , 1. , 0. , 0.4, 0.6],\n",
       "       [1. , 1. , 1. , 0. , 0.5, 0.5],\n",
       "       [1. , 1. , 1. , 0. , 0.6, 0.4],\n",
       "       [1. , 1. , 1. , 0. , 0.7, 0.3],\n",
       "       [1. , 1. , 1. , 0. , 0.8, 0.2],\n",
       "       [1. , 1. , 1. , 0. , 0.9, 0.1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:,0:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 1. , 1. , 0. , 0.8, 0.2],\n",
       "       [1. , 1. , 0. , 0. , 0.5, 0.5],\n",
       "       [1. , 1. , 1. , 0. , 0.5, 0.5],\n",
       "       [0. , 1. , 0. , 1. , 0.5, 0.5],\n",
       "       [1. , 1. , 1. , 0. , 0.6, 0.4],\n",
       "       [1. , 1. , 1. , 0. , 0.9, 0.1],\n",
       "       [1. , 1. , 1. , 0. , 0.7, 0.3],\n",
       "       [1. , 1. , 1. , 0. , 0.4, 0.6]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "clf = MLPClassifier(hidden_layer_sizes=(256,128,64,32),activation=\"relu\",random_state=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 1. , 1. , 0. , 0.1, 0.9],\n",
       "       [1. , 1. , 1. , 0. , 0.2, 0.8],\n",
       "       [1. , 1. , 1. , 0. , 0.3, 0.7]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1, 1, 1, 0, 0.2343, 1- .2343]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
